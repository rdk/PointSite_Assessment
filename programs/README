
#============== installation ==================#
#-> 1. p2rank
https://github.com/rdk/p2rank

[note]:
To install p2rank, we need gradle -> https://gradle.org/install/
Also, export PATH=$PATH:/opt/gradle/gradle-5.6.2/bin


#-> 2. fpocket
https://github.com/Discngine/fpocket

[note]:
To install fpocket, we need the molfile plugin from VMD:
sudo apt-get install libnetcdf-dev
or,
sudo yum install netcdf-devel.x86_64


#-> 3. sitehound
http://scbx.mssm.edu/sitehound/sitehound-download/download.html
(NOT open source, highly unrecommended !!)

[note]:
To succesfully run sitehound, we need install A LOT OF 32-bit libraries, such as libX11.so.6 and libSM.so.6 !!!

[procedures]:
In order to install them, please first to install the 64-bit version libraries by the following command:
`sudo yum install libSM libX11`

Then, use yum provides to search for the required 32-bit libraries of those missing files, for example,
`yum provides libX11.so.6`

It shall come with the required libraries as follows:
`libX11-1.6.7-2.el7.i686`

Then, install this library by typing sudo yum install libX11.i686

[bugs]:
It is well known that sitehound will report a bug if the input PDB contains ANY missing atoms which is very common.
Thus, to handle such situations, we have to "reconstruct" the PDB with the following module:
`BuildModel_Package/util/Complete_PDB.sh 5ow0A_xyz.pdb /tmp/5ow0A_xyz.pdb`



#-> 4. selenium
This is the package for command-line based Web Server submission for deepsite and metapocket2





#============== Part I: run each method for a given dataset ==============#
#-> 0. initialization
#-- parameter setting
cur_root=`pwd`
cpunum=32
threadnum=8
buildmod=/home/wangs0c/WS_Program/RaptorX-Threading/BuildModel_Package
#-- input data preparation
data=blind_data
indir=`pwd`/example/blind
awk '{print $0"_xyz.pdb"}' `pwd`/example/blind_list > $indir/$data
#-- output data preparation
outdir=`pwd`/example/blind_out
mkdir -p $outdir


#------------ run comparison methods ----------#
#-> 1. p2rank
./p2rank_run.sh $data $indir $outdir $cpunum $cur_root/p2rank

#-> 2. fpocket
./fpocket_run.sh $data $indir $outdir $cpunum $cur_root/fpocket $cur_root/util

#-> 3. sitehound
./sitehound_run.sh $data $indir $outdir $cpunum $cur_root/sitehound $buildmod $cur_root/util
#[note]: neglect those "errors" as sitehound can't deal with non-standard amino acids.

#-> 4. deepsite (not recommend to run, as it will submit the jobs to the website and need 300 to 500 seconds for each job!!)
#               (also, the maximal length for deepsite shall below 1000 amino acids!!)
#./deepsite_run.sh $data $indir $outdir $threadnum $cur_root/deepsite

#-> 5. metapocket2 (not recommend to run, as it will submit the jobs to the website and need 300 to 500 seconds for each job!!)
#./metapocket2_run.sh $data $indir $outdir $threadnum $cur_root/metapocket2

#-> TER. remove the created data file
rm -f $indir/$data



#============== Part II: run assessment for each method ===============#
#-- parameter setting
cur_root=`pwd`
cpunum=32
cutoff_truth=6.5
cutoff_pred=6.5
method_list=`pwd`/method_list
#-- input data preparation
suffix=blind_data
list=`pwd`/example/blind_list
gt_dir=`pwd`/example/blind_gt
pred_dir=`pwd`/example/blind_out
#-- output data preparation
outdir=/tmp/tmp_assess
mkdir -p $outdir



#--- root input/output ---#
root_input=/home/wangs0c/GitBucket/PointSite_TestData/
root_output=/home/wangs0c/GitBucket/PointSite_Assessment/testset_result/


#--- for each cutoff_pred
for cutoff_pred in 4.5 5.5 6.5
do
echo "#++++++++++++++++++++ cutoff_pred $cutoff_pred +++++++++++++++#"

#--- for each dataset ----#
for i in `cat dataset_list`
do

#-> get data name
orig_data=`echo $i | cut -d '|' -f 1`
proc_data=`echo $i | cut -d '|' -f 2`
echo "#=================== data $orig_data ==================#"
#-> define input
suffix=${proc_data}_data
list=$root_input/${orig_data}_data/data_list
gt_dir=$root_input/${orig_data}_data/data
pred_dir=$root_output/${proc_data}_out


#------------ run assessment for each method ----------#
rm -f assess_proc
for method in `cat $method_list`;
do
	mkdir -p $outdir/${method}_${suffix}
	#for param in 4.0 4.5 5.0 5.5 6.0 6.5 7.0 7.5 8.0 8.5 9.0 9.5 10.0
	for param in 4.0
	do
		for i in `cat $list`;
		do
			echo "$cur_root/util/LigBind_Assess $gt_dir/${i}_atom.xyz $gt_dir/${i}_lig.xyz $pred_dir/${method}_${suffix}/${i}_xyz_out/${i}_xyz.surface $cutoff_truth $cutoff_pred $param > $outdir/${method}_${suffix}/${i}.assess_$param" >> assess_proc
		done
	done
done
$cur_root/util/distribute_bash.sh assess_proc $cpunum $cur_root
rm -f assess_proc


#------------ collect results ---------------#
for method in `cat $method_list`;
do
	echo "#----------- method: $method ------------#"
	#for param in 4.0 4.5 5.0 5.5 6.0 6.5 7.0 7.5 8.0 8.5 9.0 9.5 10.0
	for param in 4.0
	do
		echo "#-> param: $param"
		rm -f $outdir/${method}_${suffix}.assess_$param
		for i in `cat $list`;
		do
			reso=`head -n1 $outdir/${method}_${suffix}/${i}.assess_$param`
			if [ "$reso" != "" ]
			then
				echo "$i $reso" >> $outdir/${method}_${suffix}.assess_$param

			fi
		done
		awk 'BEGIN{a=0;b=0;c=0;d=0;e=0;f=0;g=0;h=0;z=0;y=0;}{if(NF==26){a+=$4;b+=$6;c+=$8;d+=$12;e+=$14;f+=$19;g+=$21;z+=$24;y+=$26;h++}}END{print a/c" "b/c" "d/c" "e/c" "f/h" "g/h" "c" "h" "z/h" "y/h}' $outdir/${method}_${suffix}.assess_$param
	done
done

done

done




#============== Part III: assess PointSite's IoU =========================#
#-- parameter setting
cur_root=`pwd`
cpunum=32
#-- input data preparation
suffix=blind_data
list=`pwd`/example/blind_list
gt_dir=`pwd`/example/blind_gt
pred_dir=`pwd`/example/blind_out
pt_dir=$pred_dir/pointsite_$suffix
#-- output data preparation
outdir=/tmp/tmp_pointsite
mkdir -p $outdir


#--- root input/output ---#
root_input=/home/wangs0c/GitBucket/PointSite_TestData/
root_output=/home/wangs0c/GitBucket/PointSite_Assessment/testset_result/

#--- for each dataset ----#
for i in `cat dataset_list`
do

#-> get data name
orig_data=`echo $i | cut -d '|' -f 1`
proc_data=`echo $i | cut -d '|' -f 2`
echo "#=================== data $orig_data ==================#"
#-> define input
suffix=${proc_data}_data
list=$root_input/${orig_data}_data/data_list
gt_dir=$root_input/${orig_data}_data/data
pred_dir=$root_output/${proc_data}_out
pt_dir=$pred_dir/pointsite_$suffix

#------------ run PointSite_IoU for each method ----------#
rm -f ptassess_proc
#for method in `cat $method_list`;
for method in pointsite
do
	mkdir -p $outdir/${method}_${suffix}
	for i in `cat $list`;
	do
		echo "$cur_root/util/PointSite_IoU $gt_dir/${i}_atom.xyz $pt_dir/${i}_xyz_out/${i}_atom.xyz > $outdir/${method}_${suffix}/${i}.assess_iou" >> ptassess_proc
	done
done
$cur_root/util/distribute_bash.sh ptassess_proc $cpunum $cur_root
rm -f ptassess_proc


#------------ collect results ---------------#
#for method in `cat $method_list`;
for method in pointsite
do
	echo "#----------- method: $method ------------#"
	rm -f $outdir/${method}_${suffix}.assess_iou
	for i in `cat $list`;
	do
		reso=`head -n1 $outdir/${method}_${suffix}/${i}.assess_iou`
		if [ "$reso" != "" ]
		then
			echo "$i $reso" >> $outdir/${method}_${suffix}.assess_iou
		fi
	done
	awk 'BEGIN{a=0;b=0;c=0;}{if(NF==5){a+=$3;b+=$5;c++;}}END{print a/c" "b/c" "c}' $outdir/${method}_${suffix}.assess_iou
done

done







#============== Part IV: use PointSite to help each method ===============#
#-- parameter setting
cur_root=`pwd`
cpunum=32
dist_thres=6.5
ratio_thres=0.1
method_list=`pwd`/method_list
#-- input data preparation
suffix=blind_data
list=`pwd`/example/blind_list
gt_dir=`pwd`/example/blind_gt
pred_dir=`pwd`/example/blind_out
pt_dir=$pred_dir/pointsite_$suffix
#-- output data preparation
outdir=/tmp/tmp_pointsite
mkdir -p $outdir



#--- root input/output ---#
root_input=/home/wangs0c/GitBucket/PointSite_TestData/
root_output=/home/wangs0c/GitBucket/PointSite_Assessment/testset_result/




#--- for dist_thres ----#
for dist_thres in 4.5 5.5 6.5
do
echo "#++++++++++++++++++++ dist_thres $dist_thres +++++++++++++++#"

for ratio_thres in 0.1 0.2 0.3
do
echo "#||||||||||||||||||||| ratio_thres $ratio_thres |||||||||||||#"


#--- for each dataset ----#
for i in `cat dataset_list`
do

#-> get data name
orig_data=`echo $i | cut -d '|' -f 1`
proc_data=`echo $i | cut -d '|' -f 2`
echo "#=================== data $orig_data ==================#"
#-> define input
suffix=${proc_data}_data
list=$root_input/${orig_data}_data/data_list
gt_dir=$root_input/${orig_data}_data/data
pred_dir=$root_output/${proc_data}_out
pt_dir=$pred_dir/pointsite_$suffix


#------------ run PointSite_Merge for each method ----------#
rm -f ptsave_proc
for method in `cat $method_list`; 
#for method in sitehound
do 
	mkdir -p $outdir/${method}_${suffix}
	#for param in 4.0 4.5 5.0 5.5 6.0 6.5 7.0 7.5 8.0 8.5 9.0 9.5 10.0
	for param in 4.0
	do
		for i in `cat $list`; 
		do 
			echo "$cur_root/util/PointSite_Merge $pt_dir/${i}_xyz_out/${i}_atom.xyz $gt_dir/${i}_lig.xyz $pred_dir/${method}_${suffix}/${i}_xyz_out/${i}_xyz.surface $dist_thres $ratio_thres $param 1> $outdir/${method}_${suffix}/${i}.assess_$param 2> $outdir/${method}_${suffix}/${i}.result_$param " >> ptsave_proc
		done
	done
done
$cur_root/util/distribute_bash.sh ptsave_proc $cpunum $cur_root
rm -f ptsave_proc


#------------ collect results ---------------#
for method in `cat $method_list`;
#for method in sitehound
do
	echo "#----------- method: $method ------------#"
	#for param in 4.0 4.5 5.0 5.5 6.0 6.5 7.0 7.5 8.0 8.5 9.0 9.5 10.0
	for param in 4.0
	do
		echo "#-> param: $param"
		rm -f $outdir/${method}_${suffix}.assess_$param
		for i in `cat $list`;
		do
			reso=`head -n1 $outdir/${method}_${suffix}/${i}.assess_$param`
			if [ "$reso" != "" ]
			then
				echo "$i $reso" >> $outdir/${method}_${suffix}.assess_$param
			fi
		done
		awk 'BEGIN{a=0;b=0;c=0;d=0;e=0;f=0;g=0;h=0;z=0;y=0;}{if(NF==26){a+=$4;b+=$6;c+=$8;d+=$12;e+=$14;f+=$19;g+=$21;z+=$24;y+=$26;h++}}END{print a/c" "b/c" "d/c" "e/c" "f/h" "g/h" "c" "h" "z/h" "y/h}' $outdir/${method}_${suffix}.assess_$param
		#awk 'BEGIN{a=0;b=0;c=0;d=0;e=0;f=0;g=0;h=0;z=0;y=0;}{if(NF==26){a+=$4;b+=$6;c+=$8;d+=$12;e+=$14;f+=$19;g+=$21;z+=$24;y+=$26;h++}}END{print a/c" "d/c}' $outdir/${method}_${suffix}.assess_$param
	done
done

done

done

done




